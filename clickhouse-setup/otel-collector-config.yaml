receivers:
  filelog/dockercontainers:
    include: [  "/nginx_log_path" ]
    start_at: end
    include_file_path: true
    include_file_name: false
    operators:
    - type: regex_parser
      id: parse_nginx
      regex: '^\[(?P<date>\d{1,2}\/\w{3}\/\d{1,4}(:[0-9]{1,2}){3} \+([0-9]){1,4})\] (?P<remote_user>([0-9]{1,3}\.){3}[0-9]{1,3}) - - (?P<http_method>(GET|POST|HEAD|PUT|DELETE|TRACE|CONNECT)) (-|(?P<http_path>\S+))? (-|(?P<http_request_length>\d+))? (-|(?P<http_status_code>\d+))? (-|(?P<newtwork_bytes_sent>\d+)) (-|(?P<network_body_bytes_sent>\d+))? (-|(?P<referer>\S+))? "(?P<http_user_agent>[^\\]?(.*?[^\\]))" (?P<dest_ip>([0-9]{1,3}\.){3}[0-9]{1,3}):(?P<network_dest_port>\d+) (-|(?P<network_dest_status_code>\d+))?[ ]*(-|(?P<network_dest_response_time>([0-9]*[.])?[0-9]+))?[ ]*(-|(?P<network_dest_connect_time>([0-9]*[.])?[0-9]+))?[ ]*(-|(?P<network_destination_header_time>([0-9]*[.])?[0-9]+))?[ ]*(-|(?P<duration_in_s>([0-9]*[.])?[0-9]+))?[ ]*(-|"(?P<http_forwarded_for>(.*?[^\\]))")?[ ]*(-|(?P<network_destination_service>\w+))?[ ]*(-|"(?P<network_client_type>(.*?[^\\]))")?[ ]*(-|"(?P<device_id>(.*?[^\\]))")?[ ]*(-|"(?P<http_request_id>(.*?[^\\]))")?[ ]*(-|"(?P<trace_id>(.*?[^\\]))")?[ ]*(-|"(?P<span_id>(.*?[^\\]))")?[ ]*(-|(?P<hostname>\w+))?'
      output: remove-date-attr
      timestamp:
        parse_from: attributes.date
        #12/Nov/2022:04:05:02 +0000
        layout: "%d/%b/%Y:%H:%M:%S %z"
      trace:
        trace_id:
          parse_from: attributes.trace_id
        span_id:
          parse_from: attributes.span_id
      on_error: send

    - type: remove
      id: remove-date-attr
      field: attributes.date
      output: remove-span-id
    - type: remove
      id: remove-span-id
      field: attributes.span_id
      output: remove-trace-id
    - type: remove
      id: remove-trace-id
      field: attributes.trace_id
  opencensus:
    endpoint: 0.0.0.0:55678
  otlp/spanmetrics:
    protocols:
      grpc:
        endpoint: localhost:12345
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318
  jaeger:
    protocols:
      grpc:
        endpoint: 0.0.0.0:14250
      thrift_http:
        endpoint: 0.0.0.0:14268
      # thrift_compact:
      #   endpoint: 0.0.0.0:6831
      # thrift_binary:
      #   endpoint: 0.0.0.0:6832
  hostmetrics:
    collection_interval: 60s
    scrapers:
      cpu: {}
      load: {}
      memory: {}
      disk: {}
      filesystem: {}
      network: {}

processors:
  batch:
    send_batch_size: 10000
    send_batch_max_size: 11000
    timeout: 10s
  signozspanmetrics/prometheus:
    metrics_exporter: prometheus
    latency_histogram_buckets: [100us, 1ms, 2ms, 6ms, 10ms, 50ms, 100ms, 250ms, 500ms, 1000ms, 1400ms, 2000ms, 5s, 10s, 20s, 40s, 60s ]
    dimensions_cache_size: 10000
    dimensions:
      - name: service.namespace
        default: default
      - name: deployment.environment
        default: default
  filter:
    logs:
      exclude:
        match_type: strict
        record_attributes:
          - Key: continue
            Value: 'no'
        # bodies:
        # - '.* (([0-9]{1,3}.)+[0-9]{1,3}) - - (?P<http_method>(GET|POST|HEAD|PUT|DELETE|TRACE|CONNECT)).*'
          
  # typecast attributes
  attributes/ngix_attributes:
    actions:
      - key: http_status_code
        action: convert
        converted_type: int
      - key: http_request_length
        action: convert
        converted_type: int
      - key: network_dest_connect_time
        action: convert
        converted_type: double
      - key: network_dest_response_time
        action: convert
        converted_type: double
      - key: duration_in_s
        action: convert
        converted_type: double
  # memory_limiter:
  #   # 80% of maximum memory up to 2G
  #   limit_mib: 1500
  #   # 25% of limit up to 2G
  #   spike_limit_mib: 512
  #   check_interval: 5s
  #
  #   # 50% of the maximum memory
  #   limit_percentage: 50
  #   # 20% of max memory usage spike expected
  #   spike_limit_percentage: 20
  # queued_retry:
  #   num_workers: 4
  #   queue_size: 100
  #   retry_on_failure: true
  resourcedetection:
    # Using OTEL_RESOURCE_ATTRIBUTES envvar, env detector adds custom labels.
    detectors: [env, system] # include ec2 for AWS, gce for GCP and azure for Azure.
    timeout: 2s
    override: false

extensions:
  health_check:
    endpoint: 0.0.0.0:13133
  zpages:
    endpoint: 0.0.0.0:55679
  pprof:
    endpoint: 0.0.0.0:1777

exporters:
  # logging:
  #   loglevel: debug
  clickhousetraces:
    datasource: tcp://clickhouse:9000/?database=signoz_traces
  clickhousemetricswrite:
    endpoint: tcp://clickhouse:9000/?database=signoz_metrics
    resource_to_telemetry_conversion:
      enabled: true
  prometheus:
    endpoint: 0.0.0.0:8889
  # logging: {}

  clickhouselogsexporter:
    dsn: tcp://clickhouse:9000/
    timeout: 5s
    sending_queue:
      queue_size: 100
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s

service:
  telemetry:
    metrics:
      address: 0.0.0.0:8888
    logs:
      level: "debug"
  extensions:
    - health_check
    - zpages
    - pprof
  pipelines:
    traces:
      receivers: [jaeger, otlp]
      processors: [signozspanmetrics/prometheus, batch]
      exporters: [clickhousetraces]
    metrics:
      receivers: [otlp]
      processors: [batch]
      exporters: [clickhousemetricswrite]
    metrics/hostmetrics:
      receivers: [hostmetrics]
      processors: [resourcedetection, batch]
      exporters: [clickhousemetricswrite]
    metrics/spanmetrics:
      receivers: [otlp/spanmetrics]
      exporters: [prometheus]
    logs:
      receivers: [otlp, filelog/dockercontainers]
      processors: [batch, filter, attributes/ngix_attributes]
      exporters: [clickhouselogsexporter]
